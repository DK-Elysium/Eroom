# ======================= ì´ë ¥ì„œ OCR â†’ CSV íŒŒì´í”„ë¼ì¸ (ê°œì„  ë²„ì „) =======================
# ì‚¬ìš©ë²•: python imageScanner.py --input /path/to/pdf_or_folder --out resume_dataset.csv

import os
import re
import argparse
from typing import List, Dict, Any, Optional
from datetime import datetime

import fitz  # PyMuPDF
from PIL import Image
import numpy as np
import pandas as pd
import easyocr

# ---------------------------
# 1) ë¼ë²¨ ìŠ¤í‚¤ë§ˆ
# ---------------------------
RESUME_LABELS = {
    "school": None, #í•™êµ ì´ë¦„ 
    "major" : None, #ì „ê³µ ì´ë¦„
    "gpa" : None, #í•™ì 

    "intern_company_scale" : None, #ì¸í„´ íšŒì‚¬ ê·œëª¨
    "intern_total_months" : 0, #ì¸í„´ ì´ ê°œì›” ìˆ˜
    "intern_count" : 0, #ì¸í„´ íšŸìˆ˜

    "award_level" : None, #ìˆ˜ìƒ ë ˆë²¨ ìš”ì•½

    "project_count" : 0, #í”„ë¡œì íŠ¸ ê°œìˆ˜
    "cert_count" : 0, #ìê²©ì¦ ê°œìˆ˜

    "has_language_cert" : False, #ì–´í•™ ìê²©ì¦ ë³´ìœ  ì—¬ë¶€
    "overseas_experience" : None, #í•´ì™¸ ê²½í—˜ ì¢…ë¥˜

    "company_size" : None, #í¬ë§ íšŒì‚¬ ê·œëª¨
    "industry" : None, #í¬ë§ ì‚°ì—… ë¶„ì•¼
    "job_role" : None, #í¬ë§ ì§ë¬´

}

# ---------------------------
# 2) ì°¸ì¡° ë°ì´í„°
# ---------------------------

# ëŒ€ê¸°ì—… ë¦¬ìŠ¤íŠ¸ (í™•ì¥ ê°€ëŠ¥)
LARGE_COMPANIES = [
    "ì‚¼ì„±", "Samsung", "LG", "SK", "í˜„ëŒ€", "Hyundai", "ê¸°ì•„", "Kia",
    "í¬ìŠ¤ì½”", "POSCO", "í•œí™”", "Hanwha", "ë¡¯ë°", "Lotte", "GS", "ë‘ì‚°", "Doosan",
    "ë„¤ì´ë²„", "Naver", "ì¹´ì¹´ì˜¤", "Kakao", "ì¿ íŒ¡", "Coupang", "ë°°ë‹¬ì˜ë¯¼ì¡±", 
    "êµ¬ê¸€", "Google", "ë©”íƒ€", "Meta", "ì•„ë§ˆì¡´", "Amazon", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "Microsoft",
    "ì• í”Œ", "Apple", "í…ŒìŠ¬ë¼", "Tesla", "ë„·í”Œë¦­ìŠ¤", "Netflix"
]

# ì¤‘ê²¬ê¸°ì—… í‚¤ì›Œë“œ
MIDSIZE_KEYWORDS = ["ì¤‘ê²¬", "ì½”ìŠ¤ë‹¥", "KOSDAQ", "ìƒì¥"]

# ---------------------------
# 3) PDF â†’ ì´ë¯¸ì§€
# ---------------------------
def pdf_to_images(pdf_path: str, dpi: int = 200) -> List[Image.Image]:
    """PDFë¥¼ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    images: List[Image.Image] = []
    doc = fitz.open(pdf_path)
    for page in doc:
        pix = page.get_pixmap(dpi=dpi, alpha=False)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    doc.close()
    return images

# ---------------------------
# 4) OCR ìˆ˜í–‰
# ---------------------------
def ocr_images(images: List[Image.Image], languages: List[str]) -> str:
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    reader = easyocr.Reader(languages, gpu=False)
    all_texts: List[str] = []
    
    for img in images:
        texts = reader.readtext(np.array(img), detail=0)
        page_text = "\n".join(t.strip() for t in texts if t.strip())
        all_texts.append(page_text)
    
    return "\n".join(all_texts)



# ---------------------------
# 7) íšŒì‚¬ ê·œëª¨ ë¶„ë¥˜
# ---------------------------
def classify_company_scale(company_name: str) -> str:
    """íšŒì‚¬ë¥¼ ëŒ€ê¸°ì—…/ì¤‘ê²¬/ì¤‘ì†Œë¡œ ë¶„ë¥˜"""
    if not company_name:
        return "ì¤‘ì†Œ"
    
    # ëŒ€ê¸°ì—… ì²´í¬
    for large_comp in LARGE_COMPANIES:
        if large_comp.lower() in company_name.lower():
            return "ëŒ€ê¸°ì—…"
    
    # ì¤‘ê²¬ê¸°ì—… ì²´í¬
    for keyword in MIDSIZE_KEYWORDS:
        if keyword in company_name:
            return "ì¤‘ê²¬"
    
    return "ì¤‘ì†Œ"

# ---------------------------
# 8) ìˆ˜ìƒ ê·œëª¨ ë¶„ë¥˜
# ---------------------------
def classify_award_scale(award_text: str) -> str:
    """ìˆ˜ìƒì„ êµ­ì œ/ì „êµ­/ì§€ì—­/êµë‚´ë¡œ ë¶„ë¥˜"""
    award_lower = award_text.lower()
    
    if any(kw in award_lower for kw in ["international", "world", "global", "êµ­ì œ", "ì„¸ê³„"]):
        return "êµ­ì œ"
    elif any(kw in award_lower for kw in ["national", "ì „êµ­", "í•œêµ­", "korea"]):
        return "ì „êµ­"
    elif any(kw in award_lower for kw in ["regional", "ì§€ì—­", "ì‹œ", "ë„"]):
        return "ì§€ì—­"
    elif any(kw in award_lower for kw in ["university", "college", "school", "ëŒ€í•™", "êµë‚´", "í•™êµ"]):
        return "êµë‚´"
    
    return "êµë‚´"  # ê¸°ë³¸ê°’

# ---------------------------
# 9) ì •ê·œì‹ í—¬í¼
# ---------------------------
def _match_first(regexes: List[re.Pattern], text: str) -> Optional[str]:
    """ì—¬ëŸ¬ ì •ê·œì‹ ì¤‘ ì²« ë²ˆì§¸ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜"""
    for rgx in regexes:
        m = rgx.search(text)
        if m:
            return m.group(1) if m.groups() else m.group(0)
    return None

# ---------------------------
# 10) í…ìŠ¤íŠ¸ íŒŒì‹± (í•µì‹¬ ë¡œì§)
# ---------------------------
def parse_text_to_features(text: str) -> Dict[str, Any]:
    """í…ìŠ¤íŠ¸ì—ì„œ ì´ë ¥ì„œ ì •ë³´ ì¶”ì¶œ"""
    data = {k: (v.copy() if isinstance(v, (list, dict)) else v) for k, v in RESUME_LABELS.items()}
    
    norm = text.replace("\r", "\n")
    lines = [ln.strip() for ln in norm.split("\n") if ln.strip()]
    lower = norm.lower()

    # ========== í•™ë ¥ ì •ë³´ ==========
    # í•™êµ ì´ë¦„
    uni = _match_first([
        re.compile(r"([A-Z][A-Za-z&.\s]{2,}University)"),
        re.compile(r"([ê°€-í£A-Za-z&.\s]{2,}ëŒ€í•™êµ)"),
        re.compile(r"([ê°€-í£A-Za-z&.\s]{2,}ëŒ€í•™)"),
    ], norm)
    data["school"] = uni
    
    # ì „ê³µ ì´ë¦„
    major = _match_first([
        re.compile(r"(Computer Science|Software Engineering|Electrical Engineering|Information Technology|Data Science)", re.I),
        re.compile(r"([ê°€-í£A-Za-z/&\s]{2,20}(?:ê³¼|í•™ê³¼|ì „ê³µ))"),
    ], norm)
    data["major"] = major
    
    # í•™ì 
        # ========== GPA / í•™ì  ==========
    gpa_value = None

    # íŒ¨í„´ 1: "GPA 3.75 / 4.5"
    m = re.search(r"GPA\s*[:=]?\s*([0-4](?:\.\d{1,2})?)\s*/\s*[0-4](?:\.\d{1,2})?", norm, re.I)
    # íŒ¨í„´ 2: "í‰ì  3.8 / 4.5"
    if not m:
        m = re.search(r"í‰ì \s*[:=]?\s*([0-4](?:\.\d{1,2})?)\s*/\s*[0-4](?:\.\d{1,2})?", norm)

    # íŒ¨í„´ 3: "GPA 3.75" (ìŠ¤ì¼€ì¼ ì—†ì´ ë‹¨ë… ìˆ«ìë§Œ ì¨ë†“ì€ ê²½ìš°)
    if not m:
        m = re.search(r"GPA\s*[:=]?\s*([0-4](?:\.\d{1,2})?)", norm, re.I)

    # íŒ¨í„´ 4: "í‰ì  3.8"
    if not m:
        m = re.search(r"í‰ì \s*[:=]?\s*([0-4](?:\.\d{1,2})?)", norm)

    if m:
        try:
            gpa_value = float(m.group(1))
        except ValueError:
            gpa_value = None

    data["gpa"] = gpa_value



    # ========== ì¸í„´ ê²½í—˜ ==========
         # ========== ì¸í„´ ê²½í—˜ ==========
    intern_patterns = [
        # íŒ¨í„´ 1: "ì¸í„´ at íšŒì‚¬ëª… 3ê°œì›”" / "Internship at ì¹´ì¹´ì˜¤ 6 months"
        re.compile(r"(ì¸í„´|Intern|Internship)\s+(?:at\s+)?([^\n,]+?)(?:\s+\()?(\d+)\s*(?:ê°œì›”|months?|mos?)", re.I),

        # íŒ¨í„´ 2: "ì¹´ì¹´ì˜¤ ì¸í„´ 3ê°œì›”" / "ë„¤ì´ë²„ Intern 6ê°œì›”"
        re.compile(r"([^\n,]+?)\s+(?:ì¸í„´|Intern).*?(\d+)\s*(?:ê°œì›”|months?)", re.I),
    ]

    intern_count = 0              # ì¸í„´ íšŸìˆ˜
    intern_total_months = 0       # ì¸í„´ ì´ ê°œì›” ìˆ˜
    intern_scales = []            # íšŒì‚¬ ê·œëª¨ë“¤ ëª¨ì•„ë‘ê¸° (ëŒ€ê¸°ì—…/ì¤‘ê²¬/ì¤‘ì†Œ ë“±)
    seen_interns = set()          # (company, months) ì¤‘ë³µ ë°©ì§€ìš©

    for pattern in intern_patterns:
        for match in pattern.finditer(norm):
            try:
                # ê·¸ë£¹ ê°œìˆ˜ì— ë”°ë¼ company / months ìœ„ì¹˜ê°€ ì¡°ê¸ˆ ë‹¤ë¦„
                if len(match.groups()) >= 3:
                    # íŒ¨í„´ 1: (ì¸í„´ë‹¨ì–´, íšŒì‚¬ëª…, ê°œì›”ìˆ˜)
                    company = match.group(2).strip()
                    months = int(match.group(3))
                elif len(match.groups()) >= 2:
                    # íŒ¨í„´ 2: (íšŒì‚¬ëª…, ê°œì›”ìˆ˜)
                    company = match.group(1).strip()
                    months = int(match.group(2))
                else:
                    continue

                # ğŸ”’ ì¤‘ë³µ ì²´í¬ (ê°™ì€ íšŒì‚¬ + ê°™ì€ ê°œì›” ìˆ˜ë©´ í•œ ë²ˆë§Œ ì¹´ìš´íŠ¸)
                key = (company, months)
                if key in seen_interns:
                    continue
                seen_interns.add(key)

                # íšŒì‚¬ ê·œëª¨ ë¶„ë¥˜ (ëŒ€ê¸°ì—…/ì¤‘ê²¬/ì¤‘ì†Œ/ê¸°íƒ€ ë“±)
                scale = classify_company_scale(company)

                # ì¸í„´ ê°œìˆ˜ +1
                intern_count += 1

                # ì´ ê°œì›” ìˆ˜ ëˆ„ì 
                intern_total_months += months

                # íšŒì‚¬ ê·œëª¨ ëª©ë¡ì— ì¶”ê°€ (ë‚˜ì¤‘ì— ì œì¼ í° ê·œëª¨ ë½‘ê¸° ìœ„í•¨)
                if scale:
                    intern_scales.append(scale)

            except Exception:
                # íŒŒì‹± ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ ê·¸ ì¼€ì´ìŠ¤ë§Œ ê±´ë„ˆëœ€
                continue

    # ì¸í„´ ê´€ë ¨ ìš”ì•½ ë¼ë²¨ ì±„ìš°ê¸°
    data["intern_count"] = intern_count
    data["intern_total_months"] = intern_total_months

    # intern_company_scale: ì—¬ëŸ¬ ì¸í„´ ì¤‘ "ì œì¼ í°" íšŒì‚¬ ê·œëª¨ í•˜ë‚˜ë§Œ ìš”ì•½í•´ì„œ ë„£ê¸°
    best_scale = None
    priority = ["ëŒ€ê¸°ì—…", "ì¤‘ê²¬", "ì¤‘ì†Œ", "ê¸°íƒ€"]

    for cand in priority:
        if cand in intern_scales:
            best_scale = cand
            break

    if best_scale is None and intern_scales:
        best_scale = intern_scales[0]

    data["intern_company_scale"] = best_scale


    # ========== ìˆ˜ìƒ ê²½ë ¥ / Award Level ìš”ì•½ ==========
    award_patterns = [
        # íŒ¨í„´ 1: "ìˆ˜ìƒ: êµë‚´ ìº¡ìŠ¤í†¤ë””ìì¸ ê²½ì§„ëŒ€íšŒ ìµœìš°ìˆ˜ìƒ", "Award: ..."
        re.compile(r"(ìˆ˜ìƒ|Award|Prize)\s*[:ï¼š]?\s*([^\n]+)", re.I),

        # íŒ¨í„´ 2: "êµë‚´ ìº¡ìŠ¤í†¤ ê²½ì§„ëŒ€íšŒ ìµœìš°ìˆ˜ìƒ ìˆ˜ìƒ", "XXX Competition Award"
        re.compile(r"([^\n]+?)\s+(?:ëŒ€íšŒ|Competition|Contest).*?(?:ìˆ˜ìƒ|ìƒ|Award|Prize)", re.I),
    ]

    award_scales = []   # "êµ­ì œ", "ì „êµ­", "ì§€ì—­", "êµë‚´" ê°™ì€ scale ë“¤ë§Œ ëª¨ì•„ë‘ê¸°

    for pattern in award_patterns:
        for match in pattern.finditer(norm):
            # ê·¸ë£¹ ê°œìˆ˜ì— ë”°ë¼ award í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            award_text = match.group(2) if len(match.groups()) >= 2 else match.group(1)
            award_text = award_text.strip()[:100]  # ë„ˆë¬´ ê¸¸ë©´ 100ìê¹Œì§€ë§Œ

            # ìˆ˜ìƒ í…ìŠ¤íŠ¸ì—ì„œ scale ë¶„ë¥˜ (êµ­ì œ/ì „êµ­/ì§€ì—­/êµë‚´/ê¸°íƒ€ ...)
            scale = classify_award_scale(award_text)
            if scale:
                award_scales.append(scale)

    # award_level: ì—¬ëŸ¬ ìˆ˜ìƒ ì¤‘ "ì œì¼ ë†’ì€" ë ˆë²¨ í•˜ë‚˜ë§Œ ê²°ì •
    # ìš°ì„ ìˆœìœ„ ì˜ˆì‹œ: êµ­ì œ > ì „êµ­ > ì§€ì—­ > êµë‚´
    best_award_level = None
    priority = ["êµ­ì œ", "ì „êµ­", "ì§€ì—­", "êµë‚´"]

    for cand in priority:
        if cand in award_scales:
            best_award_level = cand
            break

    # priority ì•ˆì— ì—†ëŠ” ìŠ¤ì¼€ì¼ë“¤ë§Œ ìˆë‹¤ë©´ (ì˜ˆ: "ê¸°íƒ€", "êµì™¸") ê·¸ ì¤‘ í•˜ë‚˜ë¼ë„ ì‚¬ìš©
    if best_award_level is None and award_scales:
        best_award_level = award_scales[0]

    data["award_level"] = best_award_level

    # ========== í”„ë¡œì íŠ¸ ê°œìˆ˜ ì¶”ì¶œ ==========
    project_patterns = [
        re.compile(r"(Project|í”„ë¡œì íŠ¸)\s*[:ï¼š]?\s*([^\n]+)", re.I),
    ]

    project_count = 0

    for pattern in project_patterns:
        for match in pattern.finditer(norm):
            proj_name = match.group(2).strip()[:100]

            # í”„ë¡œì íŠ¸ ì´ë¦„ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì¡íˆëŠ” "í”„ë¡œì íŠ¸" í‚¤ì›Œë“œ ì¡ìŒ ì œê±°
            if proj_name and len(proj_name) > 3:
                project_count += 1

    data["project_count"] = project_count

    # ========== ìê²©ì¦ ê°œìˆ˜ ì¶”ì¶œ ==========
    cert_patterns = [
        # "ìê²©ì¦: ì •ë³´ì²˜ë¦¬ê¸°ì‚¬" / "Certificate: AWS" ê°™ì€ ì¼€ì´ìŠ¤
        re.compile(r"(ìê²©ì¦|Certificate|Certification)\s*[:ï¼š]?\s*([^\n]+)", re.I),

        # "~ê¸°ì‚¬" ê³„ì—´(ì •ë³´ì²˜ë¦¬ê¸°ì‚¬, ì „ìê¸°ì‚¬ ë“±)
        re.compile(r"([ê°€-í£A-Za-z\s]+ê¸°ì‚¬)", re.I),

        # ëŒ€í‘œì ì¸ IT ìê²©ì¦ë“¤
        re.compile(r"(SQLD|ADsP|ì •ë³´ì²˜ë¦¬ê¸°ì‚¬|ë„¤íŠ¸ì›Œí¬ê´€ë¦¬ì‚¬)", re.I),
    ]

    cert_count = 0

    for pattern in cert_patterns:
        for match in pattern.finditer(norm):
            cert_name = match.group(2) if len(match.groups()) >= 2 else match.group(1)
            cert_name = cert_name.strip()[:50]

            # ë„ˆë¬´ ì§§ê±°ë‚˜ ì“°ë ˆê¸° ë§¤ì¹­ëœ ì´ë¦„ ì œê±°
            if cert_name and len(cert_name) > 2:
                cert_count += 1

    data["cert_count"] = cert_count

    
    # ========== ì–´í•™ ì ìˆ˜ ì¡´ì¬ ì—¬ë¶€ë§Œ ì¶”ì¶œ ==========
    toeic = _match_first([re.compile(r"TOEIC\s*[:=]?\s*(\d{3,4})", re.I)], norm)
    ielts = _match_first([re.compile(r"IELTS\s*[:=]?\s*(\d(?:\.\d)?)", re.I)], norm)
    toefl = _match_first([re.compile(r"TOEFL\s*[:=]?\s*(\d{2,3})", re.I)], norm)

    # ì˜ì–´ ì„±ì  ìˆëŠ”ì§€ë§Œ ì²´í¬
    has_language_cert = False
    if toeic or ielts or toefl:
        has_language_cert = True

    data["has_language_cert"] = has_language_cert


    # ========== í•´ì™¸ ê²½í—˜ ==========
        # ========== í•´ì™¸ ê²½í—˜ ë¬¸ìì—´ ì¶”ì¶œ (êµí™˜í•™ìƒ/ì–´í•™ì—°ìˆ˜/í•´ì™¸ ì¸í„´ ë“±) ==========
    overseas_patterns = [
        (re.compile(r"êµí™˜í•™ìƒ|Exchange Student|Study Abroad", re.I), "Exchange"),
        (re.compile(r"ì–´í•™ì—°ìˆ˜|Language Training", re.I), "LanguageStudy"),
        (re.compile(r"í•´ì™¸ ì¸í„´|International Intern", re.I), "OverseasIntern"),
    ]

    overseas_type = None

    for pattern, label in overseas_patterns:
        if pattern.search(norm):
            overseas_type = label
            break

    data["overseas_experience"] = overseas_type  # ë¬¸ìì—´ë¡œ ì €ì¥ (None or "êµí™˜í•™ìƒ" ë“±)


    # ======== ì§€ì› íšŒì‚¬ ë¶„ì•¼ ========
    # 1) í¬ë§ íšŒì‚¬ ê·œëª¨ (company_size)
       # ========== í¬ë§ íšŒì‚¬ ê·œëª¨ ì¶”ì¶œ (classify_company_scale ì¬í™œìš©) ==========
    hope_company = None

    # í¬ë§ íšŒì‚¬/ì§€ì› íšŒì‚¬ í…ìŠ¤íŠ¸ ì°¾ê¸°
    hope_patterns = [
        re.compile(r"(?:í¬ë§\s*íšŒì‚¬|ì§€ì›\s*íšŒì‚¬|ì§€ì›\s*ê¸°ì—…|ì…ì‚¬\s*í¬ë§)\s*[:ï¼š]?\s*([^\n]+)", re.I),
        re.compile(r"([A-Za-zê°€-í£0-9&.\s]+)\s+(?:ì…ì‚¬\s*í¬ë§|ì§€ì›í•˜ê³ ì)", re.I),
        re.compile(r"(?:at\s+)?([A-Za-zê°€-í£0-9&.\s]+)\s+ì…ì‚¬", re.I),
    ]

    for pattern in hope_patterns:
        m = pattern.search(norm)
        if m:
            hope_company = m.group(1).strip()[:50]
            break

    # íšŒì‚¬ ê·œëª¨ ë¶„ë¥˜ í•¨ìˆ˜ í™œìš©
    if hope_company:
        company_scale = classify_company_scale(hope_company)
        data["company_size"] = company_scale  # ê¸°ì¡´ í•¨ìˆ˜ ê²°ê³¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    else:
        data["company_size"] = None



    # 2) í¬ë§ ì‚°ì—… ë¶„ì•¼ (industry)
    industry = None

    # IT / ì†Œí”„íŠ¸ì›¨ì–´ / ë°ì´í„° / AI
    if re.search(r"IT|ì†Œí”„íŠ¸ì›¨ì–´|SW|ê°œë°œì|ë°±ì—”ë“œ|í”„ë¡ íŠ¸ì—”ë“œ|ì›¹\s*ê°œë°œ|ì•±\s*ê°œë°œ|ì¸ê³µì§€ëŠ¥|AI|ë°ì´í„°\s*ì‚¬ì´ì–¸ìŠ¤|ë°ì´í„°\s*ë¶„ì„", norm, re.I):
        industry = "IT/Software"
    # ê¸ˆìœµ
    elif re.search(r"ê¸ˆìœµ|ì€í–‰|ì¦ê¶Œ|ë³´í—˜|í•€í…Œí¬|Fintech", norm, re.I):
        industry = "Finance"
    # ì œì¡° / ì „ì / ë°˜ë„ì²´
    elif re.search(r"ì œì¡°|Manufacturing|ìƒì‚°|ê³µì¥|ë°˜ë„ì²´|ì „ì\s*ì‚°ì—…", norm, re.I):
        industry = "Manufacturing"
    # í—¬ìŠ¤ì¼€ì–´ / ë°”ì´ì˜¤ / ì˜ë£Œ
    elif re.search(r"í—¬ìŠ¤ì¼€ì–´|ì˜ë£Œ|ë³‘ì›|ë°”ì´ì˜¤|ì œì•½|Bio|Healthcare", norm, re.I):
        industry = "Healthcare"
    # êµìœ¡
    elif re.search(r"êµìœ¡|ì—ë“€í…Œí¬|Edtech", norm, re.I):
        industry = "Education"
    # ì»¤ë¨¸ìŠ¤ / ìœ í†µ / ì´ì»¤ë¨¸ìŠ¤
    elif re.search(r"ì»¤ë¨¸ìŠ¤|ì´ì»¤ë¨¸ìŠ¤|e[-\s]?commerce|ìœ í†µ|ë¦¬í…Œì¼", norm, re.I):
        industry = "Commerce/Retail"

    data["industry"] = industry

    # ---------------------------
    # 3) í¬ë§ ì§ë¬´ (job_role)
    # ---------------------------
    job_role = None

    # ë¨¼ì € 'í¬ë§ ì§ë¬´/ì§€ì› ì§ë¬´/ì§€ì› ë¶„ì•¼' ê°™ì€ ë‹¨ì–´ ê·¼ì²˜ì—ì„œ í•œ ë²ˆ ë” ê°•í•˜ê²Œ ì°¾ê³ ,
    # ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì•„ë„ ë¨. ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œë§Œ ì²˜ë¦¬.

    # Backend / Server
    if re.search(r"ë°±ì—”ë“œ|ì„œë²„\s*ê°œë°œ|Backend", norm, re.I):
        job_role = "Backend"
    # Frontend / Web UI
    elif re.search(r"í”„ë¡ íŠ¸ì—”ë“œ|ì›¹\s*ê°œë°œ|Frontend", norm, re.I):
        job_role = "Frontend"
    # Mobile (Android / iOS)
    elif re.search(r"ëª¨ë°”ì¼\s*ì•±|Android\s*ê°œë°œ|iOS\s*ê°œë°œ|ëª¨ë°”ì¼\s*ê°œë°œ", norm, re.I):
        job_role = "Mobile"
    # Data Analyst / Scientist
    elif re.search(r"ë°ì´í„°\s*ë¶„ì„|Data\s*Analyst|ë°ì´í„°\s*ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸|Data\s*Scientist", norm, re.I):
        job_role = "Data Scientist"
    # ML / AI Engineer
    elif re.search(r"ë¨¸ì‹ ëŸ¬ë‹|Machine\s*Learning|ML\s*Engineer|AI\s*Engineer|ì¸ê³µì§€ëŠ¥\s*ì—”ì§€ë‹ˆì–´", norm, re.I):
        job_role = "ML/AI Engineer"
    # DevOps / Infra
    elif re.search(r"DevOps|ë°ë¸Œì˜µìŠ¤|ì¸í”„ë¼\s*ì—”ì§€ë‹ˆì–´|í´ë¼ìš°ë“œ\s*ì—”ì§€ë‹ˆì–´", norm, re.I):
        job_role = "DevOps"
    # Product Manager / PM
    elif re.search(r"Product\s*Manager|PM\s*\(Product\)|í”„ë¡œë•íŠ¸\s*ë§¤ë‹ˆì €", norm, re.I):
        job_role = "Product Manager"
    # ì¼ë°˜ì ì¸ "SW Engineer", "Software Engineer"
    elif re.search(r"Software\s*Engineer|SW\s*Engineer|ì†Œí”„íŠ¸ì›¨ì–´\s*ì—”ì§€ë‹ˆì–´", norm, re.I):
        job_role = "Software Engineer"

    data["job_role"] = job_role

    return data

    





    

   

    

# ---------------------------
# 11) ë‹¨ì¼ PDF ì²˜ë¦¬
# ---------------------------
def process_resume(pdf_path: str, languages: List[str], dpi: int = 200) -> Dict[str, Any]:
    """PDF ì´ë ¥ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # 1. PDF â†’ ì´ë¯¸ì§€
        images = pdf_to_images(pdf_path, dpi=dpi)
        
        # 2. OCR ìˆ˜í–‰
        ocr_text = ocr_images(images, languages=languages)
        
        # 3. PyMuPDF í…ìŠ¤íŠ¸ ë ˆì´ì–´ë„ ì¶”ì¶œ (ë³´ê°•)
        doc = fitz.open(pdf_path)
        pdf_text = []
        for page in doc:
            pdf_text.append(page.get_text("text"))
        doc.close()
        
        # ë‘ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸° (ê¸´ ê²ƒ ìš°ì„ )
        combined_text = ocr_text if len(ocr_text) > len("\n".join(pdf_text)) else "\n".join(pdf_text)
        
        # 4. íŒŒì‹±
        features = parse_text_to_features(combined_text)
        features["source_pdf"] = os.path.basename(pdf_path)
        
        return features
        
    except Exception as e:
        row = {k: None for k in RESUME_LABELS.keys()}
        row["source_pdf"] = os.path.basename(pdf_path)
        row["error"] = str(e)
        return row

# ---------------------------
# 12) ë°°ì¹˜ ì²˜ë¦¬
# ---------------------------
def batch_build_dataset(input_path: str, languages: List[str], dpi: int = 200) -> pd.DataFrame:
    """ì—¬ëŸ¬ PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„°ì…‹ ìƒì„±"""
    paths: List[str] = []
    
    if os.path.isdir(input_path):
        for name in os.listdir(input_path):
            if name.lower().endswith(".pdf"):
                paths.append(os.path.join(input_path, name))
    elif os.path.isfile(input_path) and input_path.lower().endswith(".pdf"):
        paths = [input_path]
    else:
        raise FileNotFoundError("PDF íŒŒì¼ ë˜ëŠ” PDFê°€ ìˆëŠ” í´ë”ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    print(f"ğŸ“„ ì´ {len(paths)}ê°œì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
    
    rows = []
    for idx, pdf_path in enumerate(sorted(paths), 1):
        print(f"[{idx}/{len(paths)}] ì²˜ë¦¬ ì¤‘: {os.path.basename(pdf_path)}")
        result = process_resume(pdf_path, languages=languages, dpi=dpi)
        rows.append(result)
    
    return pd.DataFrame(rows)

# ---------------------------
# 13) CLI
# ---------------------------
def main():
    parser = argparse.ArgumentParser(
        description="ì´ë ¥ì„œ PDFë¥¼ OCRë¡œ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ CSV ë°ì´í„°ì…‹ ìƒì„±"
    )
    parser.add_argument("--input", required=True, help="PDF íŒŒì¼ ê²½ë¡œ ë˜ëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument(
        "--out",
        default="resume_dataset.csv",
        help="ì €ì¥í•  CSV íŒŒì¼ëª… (ê¸°ë³¸: resume_dataset.csv)"
    )
    parser.add_argument(
        "--dpi",
        type=int,
        default=200,
        help="PDF ë Œë”ë§ DPI (ê¸°ë³¸: 200)"
    )
    parser.add_argument(
        "--langs",
        nargs="+",
        default=["ko", "en"],
        help="EasyOCR ì–¸ì–´ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸: ko en)"
    )
    
    args = parser.parse_args()

    # CSV ì €ì¥
    df = batch_build_dataset(args.input, languages=args.langs, dpi=args.dpi)
    df.to_csv(args.out, index=False, encoding="utf-8-sig")
    print(f"\nâœ… ì™„ë£Œ! {len(df)}ê°œì˜ ì´ë ¥ì„œ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š ì €ì¥ ê²½ë¡œ: {os.path.abspath(args.out)}")

    # ===================== ìƒˆ í†µê³„ ì¶œë ¥ =====================
    print("\nğŸ“ˆ í†µê³„:")

    # 1) ì´ ì´ë ¥ì„œ ê°œìˆ˜
    print(f"  - ì´ ì´ë ¥ì„œ ê°œìˆ˜: {len(df)}ê°œ")

    # 2) school (ëŒ€í•™êµ íƒ€ì… ìš”ì•½) í†µê³„ê°€ ìˆìœ¼ë©´ ì¶œë ¥
    if "school" in df.columns:
        print("  - School ë¶„í¬:")
        print(df["school"].value_counts(dropna=False))

    # 3) ì¸í„´ / í”„ë¡œì íŠ¸ / ìê²©ì¦ í‰ê· 
    if "intern_count" in df.columns:
        print(f"  - í‰ê·  ì¸í„´ íšŸìˆ˜: {df['intern_count'].mean():.1f}íšŒ")
    if "intern_total_months" in df.columns:
        print(f"  - í‰ê·  ì¸í„´ ì´ ê°œì›” ìˆ˜: {df['intern_total_months'].mean():.1f}ê°œì›”")

    if "project_count" in df.columns:
        print(f"  - í‰ê·  í”„ë¡œì íŠ¸ ê°œìˆ˜: {df['project_count'].mean():.1f}ê°œ")

    if "cert_count" in df.columns:
        print(f"  - í‰ê·  ìê²©ì¦ ê°œìˆ˜: {df['cert_count'].mean():.1f}ê°œ")

    # 4) ì–´í•™ ìê²© ë³´ìœ  ë¹„ìœ¨
    if "has_language_cert" in df.columns:
        lang_ratio = (df["has_language_cert"] == True).mean() * 100
        print(f"  - ì–´í•™ ìê²©/ì ìˆ˜ ë³´ìœ  ë¹„ìœ¨: {lang_ratio:.1f}%")

    # 5) í•´ì™¸ ê²½í—˜ ë¶„í¬ (overseas_experience: ë¬¸ìì—´)
    if "overseas_experience" in df.columns:
        print("  - í•´ì™¸ ê²½í—˜ ìœ í˜• ë¶„í¬:")
        print(df["overseas_experience"].value_counts(dropna=False))

    # 6) í¬ë§ íšŒì‚¬ ê·œëª¨ / ì‚°ì—… / ì§ë¬´ ë¶„í¬
    if "company_size" in df.columns:
        print("  - í¬ë§ íšŒì‚¬ ê·œëª¨ ë¶„í¬:")
        print(df["company_size"].value_counts(dropna=False))

    if "industry" in df.columns:
        print("  - í¬ë§ ì‚°ì—… ë¶„ì•¼ ë¶„í¬:")
        print(df["industry"].value_counts(dropna=False))

    if "job_role" in df.columns:
        print("  - í¬ë§ ì§ë¬´ ë¶„í¬:")
        print(df["job_role"].value_counts(dropna=False))
    # =======================================================


if __name__ == "__main__":
    main()




    # python imageScanner.py  --input . --out resume_dataset.csv  
    # python imageScanner.py --input ./pdfs --out resume_dataset.csv
